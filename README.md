This project is a Machine Learning and Deep Learning based Toxic Comment Classifier designed to improve online safety.
It classifies user comments into Toxic or Non-Toxic and highlights harmful categories such as insults, hate speech, threats, profanity, and harassment.

The system combines:

A Custom ML model (TF-IDF + Logistic Regression / Deep Learning)

A Transformer-based model (Hugging Face BERT â€“ toxic-bert)

It is deployed using Streamlit with interactive Plotly visualizations.
